{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=False)\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, matthews_corrcoef, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "folder = \"/data/AIpep-clean/\"\n",
    "import matplotlib.pyplot as plt\n",
    "from vocabulary import Vocabulary\n",
    "from datasetbioactivity import Dataset\n",
    "from datasetbioactivity import collate_fn_no_activity as collate_fn\n",
    "from models import Generator\n",
    "from tqdm.autonotebook  import trange, tqdm\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(folder + \"pickles/DAASP_RNN_dataset.plk\")\n",
    "\n",
    "df_training = df[df[\"Set\"]==\"training\"]\n",
    "df_test = df[df[\"Set\"]==\"test\"]\n",
    "\n",
    "vocabulary = Vocabulary.get_vocabulary_from_sequences(df_training.Sequence.values)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" \n",
    "else:\n",
    "    device = \"cpu\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return category_i\n",
    "\n",
    "def nan_equal(a,b):\n",
    "    try:\n",
    "        np.testing.assert_equal(a,b)\n",
    "    except AssertionError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def models_are_equal(model1, model2):\n",
    "    model1.vocabulary == model2.vocabulary\n",
    "    model1.hidden_size == model2.hidden_size\n",
    "    for a,b in zip(model1.model.parameters(), model2.model.parameters()):\n",
    "        if nan_equal(a.detach().numpy(), b.detach().numpy()) == True:\n",
    "            print(\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embedding  = 100\n",
    "n_hidden = 400\n",
    "n_layers = 2\n",
    "n_epoch = 150\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(folder+\"pickles/generator_training_results.pkl\"):\n",
    "    df_training_active = df_training.query(\"activity == 1\")\n",
    "    df_test_active = df_test.query(\"activity == 1\")\n",
    "    df_training_inactive = df_training.query(\"activity == 0\")\n",
    "    df_test_inactive = df_test.query(\"activity == 0\")\n",
    "\n",
    "    training_dataset_active = Dataset(df_training_active, vocabulary, with_activity=False)\n",
    "    test_dataset_active = Dataset(df_test_active, vocabulary, with_activity=False)\n",
    "    training_dataset_inactive = Dataset(df_training_inactive, vocabulary, with_activity=False)\n",
    "    test_dataset_inactive = Dataset(df_test_inactive, vocabulary, with_activity=False)\n",
    "\n",
    "    model = Generator(n_embedding, n_hidden, n_layers, vocabulary)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.SGD(model.model.parameters(), lr = learning_rate, momentum=momentum)\n",
    "\n",
    "    # the only one used for training\n",
    "    training_dataloader_active = torch.utils.data.DataLoader(training_dataset_active, batch_size=batch_size, shuffle=True, collate_fn = collate_fn, drop_last=True, pin_memory=True, num_workers=4)\n",
    "\n",
    "    # used for evaluation\n",
    "    test_dataloader_active = torch.utils.data.DataLoader(test_dataset_active, batch_size=batch_size, shuffle=False, collate_fn = collate_fn, drop_last=False, pin_memory=True, num_workers=4)\n",
    "    training_dataloader_inactive = torch.utils.data.DataLoader(training_dataset_inactive, batch_size=batch_size, shuffle=False, collate_fn = collate_fn, drop_last=False, pin_memory=True, num_workers=4)\n",
    "    test_dataloader_inactive = torch.utils.data.DataLoader(test_dataset_inactive, batch_size=batch_size, shuffle=False, collate_fn = collate_fn, drop_last=False, pin_memory=True, num_workers=4)\n",
    "    training_dataloader_active_eval = torch.utils.data.DataLoader(training_dataset_active, batch_size=batch_size, shuffle=False, collate_fn = collate_fn, drop_last=False, pin_memory=True, num_workers=4)\n",
    "\n",
    "    training_dictionary = {}\n",
    "\n",
    "    for e in trange(1, n_epoch + 1):\n",
    "        print(\"Epoch {}\".format(e))\n",
    "        for i_batch, sample_batched in tqdm(enumerate(training_dataloader_active), total=len(training_dataloader_active) ):\n",
    "\n",
    "            seq_batched = sample_batched[0].to(model.device, non_blocking=True) \n",
    "            seq_lengths = sample_batched[1].to(model.device, non_blocking=True)\n",
    "\n",
    "            nll = model.likelihood(seq_batched, seq_lengths)\n",
    "\n",
    "            loss = nll.mean()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()  \n",
    "            torch.nn.utils.clip_grad_value_(model.model.parameters(), 2)\n",
    "            optimizer.step()\n",
    "\n",
    "        model.save(folder+\"models/RNN-generator/ep{}.pkl\".format(e))\n",
    "\n",
    "\n",
    "        print(\"\\tExample Sequences\")\n",
    "        sampled_seq = model.sample(5)\n",
    "        for s in sampled_seq:\n",
    "            print(\"\\t\\t{}\".format(model.vocabulary.tensor_to_seq(s, debug=True)))\n",
    "\n",
    "        nll_training = []\n",
    "        with torch.no_grad():\n",
    "            for i_batch, sample_batched in enumerate(training_dataloader_active_eval):    \n",
    "                seq_batched = sample_batched[0].to(model.device, non_blocking=True) \n",
    "                seq_lengths = sample_batched[1].to(model.device, non_blocking=True) \n",
    "\n",
    "                nll_training += model.likelihood(seq_batched, seq_lengths)\n",
    "\n",
    "        nll_training_active_mean = torch.stack(nll_training).mean().item()\n",
    "        print(\"\\tNLL Train Active: {}\".format(nll_training_active_mean))\n",
    "        del nll_training\n",
    "\n",
    "        nll_test = []\n",
    "        with torch.no_grad():\n",
    "            for i_batch, sample_batched in enumerate(test_dataloader_active):    \n",
    "                seq_batched = sample_batched[0].to(model.device, non_blocking=True) \n",
    "                seq_lengths = sample_batched[1].to(model.device, non_blocking=True) \n",
    "\n",
    "                nll_test += model.likelihood(seq_batched, seq_lengths)\n",
    "\n",
    "        nll_test_active_mean = torch.stack(nll_test).mean().item()\n",
    "        print(\"\\tNLL Test Active: {}\".format(nll_test_active_mean))\n",
    "        del nll_test\n",
    "\n",
    "        nll_training = []\n",
    "        with torch.no_grad():\n",
    "            for i_batch, sample_batched in enumerate(training_dataloader_inactive):    \n",
    "                seq_batched = sample_batched[0].to(model.device, non_blocking=True) \n",
    "                seq_lengths = sample_batched[1].to(model.device, non_blocking=True) \n",
    "\n",
    "                nll_training += model.likelihood(seq_batched, seq_lengths)\n",
    "\n",
    "        nll_training_inactive_mean = torch.stack(nll_training).mean().item()\n",
    "        print(\"\\tNLL Train Inactive: {}\".format(nll_training_inactive_mean))\n",
    "        del nll_training\n",
    "\n",
    "        nll_test = []\n",
    "        with torch.no_grad():\n",
    "            for i_batch, sample_batched in enumerate(test_dataloader_inactive):    \n",
    "                seq_batched = sample_batched[0].to(model.device, non_blocking=True) \n",
    "                seq_lengths = sample_batched[1].to(model.device, non_blocking=True) \n",
    "\n",
    "                nll_test += model.likelihood(seq_batched, seq_lengths)\n",
    "\n",
    "        nll_test_inactive_mean = torch.stack(nll_test).mean().item()\n",
    "        print(\"\\tNLL Test Inactive: {}\".format(nll_test_inactive_mean))\n",
    "        del nll_test\n",
    "        print()\n",
    "\n",
    "        training_dictionary[e]=[nll_training_active_mean, nll_test_active_mean, nll_training_inactive_mean, nll_test_inactive_mean]\n",
    "    \n",
    "    with open(folder+\"pickles/generator_training_results.pkl\",'wb') as fd:\n",
    "        pickle.dump(training_dictionary, fd)\n",
    "    \n",
    "else:\n",
    "    with open(folder+\"pickles/generator_training_results.pkl\",'rb') as fd:\n",
    "        training_dictionary = pickle.load(fd)\n",
    "\n",
    "min_nll_test_active = float(\"inf\")\n",
    "for epoch, training_values in training_dictionary.items():\n",
    "    nll_test_active = training_values[1]\n",
    "\n",
    "    if nll_test_active < min_nll_test_active:\n",
    "        best_epoch = epoch\n",
    "        min_nll_test_active = nll_test_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Generator.load_from_file(folder+\"models/RNN-generator/ep{}.pkl\".format(best_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_seq = df_training.Sequence.values.tolist()\n",
    "def _sample(model, n):\n",
    "    sampled_seq = model.sample(n)\n",
    "    sequences = []\n",
    "    for s in sampled_seq:\n",
    "        sequences.append(model.vocabulary.tensor_to_seq(s))\n",
    "    return sequences\n",
    "\n",
    "def novelty(seqs, list_):\n",
    "    novel_seq = []\n",
    "    for s in seqs:\n",
    "        if s not in list_:\n",
    "            novel_seq.append(s)\n",
    "    return novel_seq, (len(novel_seq)/len(seqs))*100\n",
    "\n",
    "def is_in_training(seq, list_ = training_seq):\n",
    "    if seq not in list_:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def uniqueness(seqs):\n",
    "    unique_seqs = defaultdict(int)\n",
    "    for s in seqs:\n",
    "        unique_seqs[s] += 1\n",
    "    return unique_seqs, (len(unique_seqs)/len(seqs))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.718 98.51213958835862\n"
     ]
    }
   ],
   "source": [
    "# sample\n",
    "seqs = _sample(model, 50000)\n",
    "unique_seqs, perc_uniqueness = uniqueness(seqs)\n",
    "notintraining_seqs, perc_novelty = novelty(unique_seqs, training_seq)\n",
    "print(perc_uniqueness, perc_novelty)\n",
    "\n",
    "# create dataframe\n",
    "df_generated = pd.DataFrame(list(unique_seqs.keys()), columns =['Sequence']) \n",
    "df_generated[\"Repetition\"] = df_generated[\"Sequence\"].map(lambda x: unique_seqs[x])\n",
    "df_generated[\"inTraining\"] = df_generated[\"Sequence\"].map(is_in_training)\n",
    "df_generated[\"Set\"] = \"generated\"\n",
    "\n",
    "# save\n",
    "df_generated.to_pickle(folder+\"pickles/Generated.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
